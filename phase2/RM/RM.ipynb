{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f384791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario: partitioned_best_fit_RM_10tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_10tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_10tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_10tasks_4cores\n",
      "Running scenario: global_RM_10tasks_4cores\n",
      "Running scenario: partitioned_best_fit_RM_50tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_50tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_50tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_50tasks_4cores\n",
      "Running scenario: global_RM_50tasks_4cores\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_100tasks_4cores\n",
      "Running scenario: global_RM_100tasks_4cores\n",
      "Running scenario: partitioned_best_fit_RM_200tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_200tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_200tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_200tasks_4cores\n",
      "Running scenario: global_RM_200tasks_4cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario: partitioned_best_fit_RM_400tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_400tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_400tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_400tasks_4cores\n",
      "Running scenario: global_RM_400tasks_4cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario: partitioned_best_fit_RM_500tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_500tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_500tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_500tasks_4cores\n",
      "Running scenario: global_RM_500tasks_4cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario: partitioned_best_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_first_fit_RM_100tasks_4cores\n",
      "Running scenario: partitioned_round_robin_RM_100tasks_4cores\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_8cores\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_8cores\n",
      "Running scenario: partitioned_first_fit_RM_100tasks_8cores\n",
      "Running scenario: partitioned_round_robin_RM_100tasks_8cores\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_16cores\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_16cores\n",
      "Running scenario: partitioned_first_fit_RM_100tasks_16cores\n",
      "Running scenario: partitioned_round_robin_RM_100tasks_16cores\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_32cores\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_32cores\n",
      "Running scenario: partitioned_first_fit_RM_100tasks_32cores\n",
      "Running scenario: partitioned_round_robin_RM_100tasks_32cores\n",
      "Running scenario: global_RM_100tasks_4cores\n",
      "Running scenario: global_RM_100tasks_8cores\n",
      "Running scenario: global_RM_100tasks_16cores\n",
      "Running scenario: global_RM_100tasks_32cores\n",
      "Running scenario: partitioned_best_fit_RM_50tasks_8cores\n",
      "Running scenario: global_RM_50tasks_8cores\n",
      "Running scenario: partitioned_best_fit_non_preemptive_RM_50tasks_8cores\n",
      "Running scenario: global_non_preemptive_RM_50tasks_8cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario: partitioned_best_fit_RM_100tasks_4cores_util0.25\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_4cores_util0.25\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_4cores_util0.5\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_4cores_util0.5\n",
      "Running scenario: partitioned_best_fit_RM_100tasks_4cores_util0.75\n",
      "Running scenario: partitioned_worst_fit_RM_100tasks_4cores_util0.75\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from ortools.linear_solver import pywraplp\n",
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=np.RankWarning)\n",
    "\n",
    "# Create necessary directories at the start\n",
    "os.makedirs('./results/response_vs_overrun', exist_ok=True)\n",
    "os.makedirs('./results/schedulability', exist_ok=True)\n",
    "os.makedirs('./results/milp_analysis', exist_ok=True)\n",
    "\n",
    "class Task:\n",
    "    def __init__(self, id, period, wcet, net, utilization):\n",
    "        self.id = id\n",
    "        self.period = max(1, period)\n",
    "        self.wcet = max(1, wcet)\n",
    "        self.net = min(max(1, net), self.wcet)\n",
    "        self.utilization = min(utilization, 1.0)\n",
    "        self.missed_deadlines = 0\n",
    "        self.response_time = 0\n",
    "        self.total_jobs = 0\n",
    "        self.core_assignment = -1\n",
    "        self.total_execution = 0\n",
    "        self.overrun = 0\n",
    "        self.max_response = 0\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        # For RM, tasks are compared by period (shorter period = higher priority)\n",
    "        return self.period < other.period\n",
    "\n",
    "class Job:\n",
    "    def __init__(self, task, release_time):\n",
    "        self.task = task\n",
    "        self.release_time = release_time\n",
    "        self.deadline = release_time + task.period\n",
    "        self.remaining = task.wcet\n",
    "        self.actual_execution = 0\n",
    "        self.core = -1\n",
    "        self.start_time = -1\n",
    "        self.overrun = 0\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        # For RM, jobs are compared by task period (shorter period = higher priority)\n",
    "        return self.task.period < other.task.period\n",
    "\n",
    "class Core:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.tasks = []\n",
    "        self.current_job = None\n",
    "        self.time = 0\n",
    "        self.utilization = 0\n",
    "        self.actual_utilization = 0\n",
    "        self.schedule = []\n",
    "        self.next_round_robin = 0\n",
    "        \n",
    "    def add_task(self, task):\n",
    "        if self.utilization + task.utilization <= 1.0:\n",
    "            self.tasks.append(task)\n",
    "            self.utilization += task.utilization\n",
    "            task.core_assignment = self.id\n",
    "            # Keep tasks sorted by period (RM priority order)\n",
    "            self.tasks.sort()\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.current_job = None\n",
    "        self.time = 0\n",
    "        self.actual_utilization = 0\n",
    "        self.schedule = []\n",
    "        self.next_round_robin = 0\n",
    "        for task in self.tasks:\n",
    "            task.missed_deadlines = 0\n",
    "            task.response_time = 0\n",
    "            task.total_jobs = 0\n",
    "            task.total_execution = 0\n",
    "            task.overrun = 0\n",
    "            task.max_response = 0\n",
    "\n",
    "class RMScheduler:\n",
    "    def __init__(self, num_cores, allocation_policy, is_preemptive):\n",
    "        self.num_cores = num_cores\n",
    "        self.cores = [Core(i) for i in range(num_cores)]\n",
    "        self.allocation_policy = allocation_policy\n",
    "        self.is_preemptive = is_preemptive\n",
    "        self.hyper_period = 800\n",
    "        self.total_utilization = 0\n",
    "        self.overrun_stats = defaultdict(list)\n",
    "        \n",
    "    def generate_tasks(self, num_tasks, target_utilization=None):\n",
    "        tasks = []\n",
    "        periods = [8, 10, 16, 20, 25, 32, 40, 50, 80, 100]  # RM works best with harmonic periods\n",
    "        \n",
    "        if target_utilization is None:\n",
    "            target_utilization = 0.9 * self.num_cores\n",
    "            \n",
    "        utilizations = []\n",
    "        remaining_util = target_utilization\n",
    "        for i in range(num_tasks):\n",
    "            if i == num_tasks - 1:\n",
    "                util = remaining_util\n",
    "            else:\n",
    "                util = remaining_util * (1 - random.random() ** (1/(num_tasks - i)))\n",
    "            util = max(0.05, min(0.95, util))\n",
    "            utilizations.append(util)\n",
    "            remaining_util -= util\n",
    "        \n",
    "        for i in range(num_tasks):\n",
    "            period = random.choice(periods)\n",
    "            wcet = max(1, int(period * utilizations[i]))\n",
    "            net = random.randint(max(1, int(0.7 * wcet)), wcet)\n",
    "            \n",
    "            task = Task(i, period, wcet, net, utilizations[i])\n",
    "            tasks.append(task)\n",
    "        \n",
    "        self.total_utilization = sum(t.utilization for t in tasks)\n",
    "        return tasks\n",
    "    \n",
    "    def allocate_tasks(self, tasks):\n",
    "        if 'partitioned' in self.allocation_policy:\n",
    "            for core in self.cores:\n",
    "                core.tasks = []\n",
    "                core.utilization = 0.0\n",
    "            if 'best_fit' in self.allocation_policy:\n",
    "                self._allocate_best_fit(tasks)\n",
    "            elif 'worst_fit' in self.allocation_policy:\n",
    "                self._allocate_worst_fit(tasks)\n",
    "            elif 'first_fit' in self.allocation_policy:\n",
    "                self._allocate_first_fit(tasks)\n",
    "            elif 'round_robin' in self.allocation_policy:\n",
    "                self._allocate_round_robin(tasks)\n",
    "            else:\n",
    "                self._allocate_best_fit_decreasing(tasks)\n",
    "        else:  # global scheduling\n",
    "            for core in self.cores:\n",
    "                core.tasks = tasks.copy()\n",
    "                core.tasks.sort()  # Sort by period for RM\n",
    "                core.utilization = self.total_utilization\n",
    "                for task in tasks:\n",
    "                    task.core_assignment = core.id\n",
    "    \n",
    "    def _allocate_best_fit_decreasing(self, tasks):\n",
    "        \"\"\"Best-fit decreasing heuristic for task allocation\"\"\"\n",
    "        sorted_tasks = sorted(tasks, key=lambda x: -x.utilization)\n",
    "        \n",
    "        for task in sorted_tasks:\n",
    "            best_core = None\n",
    "            min_remaining = float('inf')\n",
    "            \n",
    "            for core in self.cores:\n",
    "                remaining = 1.0 - (core.utilization + task.utilization)\n",
    "                if remaining >= 0 and remaining < min_remaining:\n",
    "                    best_core = core\n",
    "                    min_remaining = remaining\n",
    "            \n",
    "            if best_core:\n",
    "                best_core.add_task(task)\n",
    "            else:\n",
    "                min_core = min(self.cores, key=lambda x: x.utilization)\n",
    "                min_core.add_task(task)\n",
    "    \n",
    "    def _allocate_best_fit(self, tasks):\n",
    "        \"\"\"Best-fit heuristic for task allocation\"\"\"\n",
    "        for task in tasks:\n",
    "            best_core = None\n",
    "            min_remaining = float('inf')\n",
    "            \n",
    "            for core in self.cores:\n",
    "                remaining = 1.0 - (core.utilization + task.utilization)\n",
    "                if remaining >= 0 and remaining < min_remaining:\n",
    "                    best_core = core\n",
    "                    min_remaining = remaining\n",
    "            \n",
    "            if best_core:\n",
    "                best_core.add_task(task)\n",
    "            else:\n",
    "                min_core = min(self.cores, key=lambda x: x.utilization)\n",
    "                min_core.add_task(task)\n",
    "    \n",
    "    def _allocate_worst_fit(self, tasks):\n",
    "        \"\"\"Worst-fit heuristic for task allocation\"\"\"\n",
    "        for task in tasks:\n",
    "            worst_core = None\n",
    "            max_remaining = -1\n",
    "            \n",
    "            for core in self.cores:\n",
    "                remaining = 1.0 - (core.utilization + task.utilization)\n",
    "                if remaining >= 0 and remaining > max_remaining:\n",
    "                    worst_core = core\n",
    "                    max_remaining = remaining\n",
    "            \n",
    "            if worst_core:\n",
    "                worst_core.add_task(task)\n",
    "            else:\n",
    "                min_core = min(self.cores, key=lambda x: x.utilization)\n",
    "                min_core.add_task(task)\n",
    "    \n",
    "    def _allocate_first_fit(self, tasks):\n",
    "        \"\"\"First-fit heuristic for task allocation\"\"\"\n",
    "        for task in tasks:\n",
    "            allocated = False\n",
    "            for core in self.cores:\n",
    "                if core.add_task(task):\n",
    "                    allocated = True\n",
    "                    break\n",
    "            if not allocated:\n",
    "                min_core = min(self.cores, key=lambda x: x.utilization)\n",
    "                min_core.add_task(task)\n",
    "    \n",
    "    def _allocate_round_robin(self, tasks):\n",
    "        \"\"\"Round-robin task allocation\"\"\"\n",
    "        core_idx = 0\n",
    "        for task in tasks:\n",
    "            allocated = False\n",
    "            start_idx = core_idx\n",
    "            while True:\n",
    "                if self.cores[core_idx].add_task(task):\n",
    "                    allocated = True\n",
    "                    core_idx = (core_idx + 1) % self.num_cores\n",
    "                    break\n",
    "                core_idx = (core_idx + 1) % self.num_cores\n",
    "                if core_idx == start_idx:\n",
    "                    break\n",
    "            if not allocated:\n",
    "                min_core = min(self.cores, key=lambda x: x.utilization)\n",
    "                min_core.add_task(task)\n",
    "    \n",
    "    def simulate(self, tasks, max_time=800):\n",
    "        if 'partitioned' in self.allocation_policy:\n",
    "            self._simulate_partitioned(tasks, max_time)\n",
    "        else:\n",
    "            self._simulate_global(tasks, max_time)\n",
    "    \n",
    "    def _simulate_partitioned(self, tasks, max_time):\n",
    "        for core in self.cores:\n",
    "            if core.tasks:\n",
    "                if self.is_preemptive:\n",
    "                    self._simulate_core_preemptive_rm(core, max_time)\n",
    "                else:\n",
    "                    self._simulate_core_nonpreemptive_rm(core, max_time)\n",
    "    \n",
    "    def _simulate_core_preemptive_rm(self, core, max_time):\n",
    "        jobs = []\n",
    "        for task in core.tasks:\n",
    "            releases = range(0, max_time, task.period)\n",
    "            task.total_jobs = len(releases)\n",
    "            for release in releases:\n",
    "                jobs.append(Job(task, release))\n",
    "        \n",
    "        jobs.sort(key=lambda x: x.release_time)\n",
    "        ready_queue = []\n",
    "        current_job = None\n",
    "        time = 0\n",
    "        \n",
    "        while time < max_time and (jobs or ready_queue or current_job):\n",
    "            # Add newly released jobs\n",
    "            while jobs and jobs[0].release_time <= time:\n",
    "                job = jobs.pop(0)\n",
    "                heapq.heappush(ready_queue, job)\n",
    "            \n",
    "            # Handle preemption\n",
    "            if current_job and ready_queue:\n",
    "                # Preempt if new job has higher priority (shorter period)\n",
    "                if ready_queue[0].task.period < current_job.task.period:\n",
    "                    heapq.heappush(ready_queue, current_job)\n",
    "                    current_job = None\n",
    "            \n",
    "            # Get next job to execute (highest priority)\n",
    "            if not current_job and ready_queue:\n",
    "                current_job = heapq.heappop(ready_queue)\n",
    "                current_job.start_time = time\n",
    "            \n",
    "            if current_job:\n",
    "                execution = self._get_execution_time(current_job)\n",
    "                \n",
    "                # Determine how long to execute\n",
    "                next_release = jobs[0].release_time if jobs else float('inf')\n",
    "                execute_until = min(\n",
    "                    time + execution,\n",
    "                    current_job.deadline,\n",
    "                    next_release\n",
    "                )\n",
    "                execute_time = execute_until - time\n",
    "                \n",
    "                if execute_time > 0:\n",
    "                    current_job.remaining -= execute_time\n",
    "                    current_job.actual_execution += execute_time\n",
    "                    core.actual_utilization += execute_time\n",
    "                    core.schedule.append((\n",
    "                        time, \n",
    "                        execute_until, \n",
    "                        current_job.task.id,\n",
    "                        current_job.actual_execution\n",
    "                    ))\n",
    "                    time = execute_until\n",
    "                \n",
    "                # Check if job completed or missed deadline\n",
    "                if current_job.remaining <= 0:\n",
    "                    response = time - current_job.release_time\n",
    "                    current_job.task.response_time = max(\n",
    "                        current_job.task.response_time,\n",
    "                        response\n",
    "                    )\n",
    "                    current_job.task.max_response = max(\n",
    "                        current_job.task.max_response,\n",
    "                        response\n",
    "                    )\n",
    "                    current_job.task.total_execution += current_job.actual_execution\n",
    "                    current_job = None\n",
    "                elif time >= current_job.deadline:\n",
    "                    current_job.task.missed_deadlines += 1\n",
    "                    current_job.task.response_time = max(\n",
    "                        current_job.task.response_time,\n",
    "                        current_job.deadline - current_job.release_time\n",
    "                    )\n",
    "                    current_job.task.max_response = max(\n",
    "                        current_job.task.max_response,\n",
    "                        current_job.deadline - current_job.release_time\n",
    "                    )\n",
    "                    current_job = None\n",
    "            else:\n",
    "                # No jobs to execute, advance to next event\n",
    "                next_event = min(\n",
    "                    jobs[0].release_time if jobs else float('inf'),\n",
    "                    ready_queue[0].deadline if ready_queue else float('inf')\n",
    "                )\n",
    "                time = min(next_event, max_time)\n",
    "        \n",
    "        # Calculate actual utilization\n",
    "        if max_time > 0:\n",
    "            core.actual_utilization /= max_time\n",
    "\n",
    "    def _simulate_core_nonpreemptive_rm(self, core, max_time):\n",
    "        jobs = []\n",
    "        for task in core.tasks:\n",
    "            releases = range(0, max_time, task.period)\n",
    "            task.total_jobs = len(releases)\n",
    "            for release in releases:\n",
    "                jobs.append(Job(task, release))\n",
    "        \n",
    "        jobs.sort(key=lambda x: x.release_time)\n",
    "        ready_queue = []\n",
    "        current_job = None\n",
    "        time = 0\n",
    "        \n",
    "        while time < max_time and (jobs or ready_queue or current_job):\n",
    "            # Add newly released jobs\n",
    "            while jobs and jobs[0].release_time <= time:\n",
    "                job = jobs.pop(0)\n",
    "                heapq.heappush(ready_queue, job)\n",
    "            \n",
    "            # Get next job to execute (highest priority)\n",
    "            if not current_job and ready_queue:\n",
    "                current_job = heapq.heappop(ready_queue)\n",
    "                current_job.start_time = time\n",
    "            \n",
    "            if current_job:\n",
    "                execution = self._get_execution_time(current_job)\n",
    "                execute_time = min(execution, current_job.remaining)\n",
    "                \n",
    "                if execute_time > 0:\n",
    "                    current_job.remaining -= execute_time\n",
    "                    current_job.actual_execution += execute_time\n",
    "                    core.actual_utilization += execute_time\n",
    "                    core.schedule.append((\n",
    "                        time, \n",
    "                        time + execute_time, \n",
    "                        current_job.task.id,\n",
    "                        current_job.actual_execution\n",
    "                    ))\n",
    "                    time += execute_time\n",
    "                \n",
    "                # Check if job completed or missed deadline\n",
    "                if current_job.remaining <= 0:\n",
    "                    response = time - current_job.release_time\n",
    "                    current_job.task.response_time = max(\n",
    "                        current_job.task.response_time,\n",
    "                        response\n",
    "                    )\n",
    "                    current_job.task.max_response = max(\n",
    "                        current_job.task.max_response,\n",
    "                        response\n",
    "                    )\n",
    "                    current_job.task.total_execution += current_job.actual_execution\n",
    "                    current_job = None\n",
    "                elif time >= current_job.deadline:\n",
    "                    current_job.task.missed_deadlines += 1\n",
    "                    current_job.task.response_time = max(\n",
    "                        current_job.task.response_time,\n",
    "                        current_job.deadline - current_job.release_time\n",
    "                    )\n",
    "                    current_job.task.max_response = max(\n",
    "                        current_job.task.max_response,\n",
    "                        current_job.deadline - current_job.release_time\n",
    "                    )\n",
    "                    current_job = None\n",
    "            else:\n",
    "                # No jobs to execute, advance to next event\n",
    "                next_event = min(\n",
    "                    jobs[0].release_time if jobs else float('inf'),\n",
    "                    ready_queue[0].deadline if ready_queue else float('inf')\n",
    "                )\n",
    "                time = min(next_event, max_time)\n",
    "        \n",
    "        # Calculate actual utilization\n",
    "        if max_time > 0:\n",
    "            core.actual_utilization /= max_time\n",
    "\n",
    "    def _simulate_global(self, tasks, max_time):\n",
    "        jobs = []\n",
    "        for task in tasks:\n",
    "            releases = range(0, max_time, task.period)\n",
    "            task.total_jobs = len(releases)\n",
    "            for release in releases:\n",
    "                jobs.append(Job(task, release))\n",
    "        \n",
    "        jobs.sort(key=lambda x: x.release_time)\n",
    "        ready_queue = []\n",
    "        current_jobs = {core.id: None for core in self.cores}\n",
    "        time = 0\n",
    "        \n",
    "        while time < max_time and (jobs or ready_queue or any(current_jobs.values())):\n",
    "            # Add newly released jobs\n",
    "            while jobs and jobs[0].release_time <= time:\n",
    "                job = jobs.pop(0)\n",
    "                heapq.heappush(ready_queue, job)\n",
    "            \n",
    "            # Handle preemption if enabled\n",
    "            if self.is_preemptive:\n",
    "                for core_id, current_job in current_jobs.items():\n",
    "                    if current_job and ready_queue:\n",
    "                        if ready_queue[0].task.period < current_job.task.period:\n",
    "                            heapq.heappush(ready_queue, current_job)\n",
    "                            current_jobs[core_id] = None\n",
    "            \n",
    "            # Assign jobs to idle cores\n",
    "            available_cores = [cid for cid, job in current_jobs.items() if job is None]\n",
    "            while available_cores and ready_queue:\n",
    "                core_id = available_cores.pop(0)\n",
    "                job = heapq.heappop(ready_queue)\n",
    "                current_jobs[core_id] = job\n",
    "                job.core = core_id\n",
    "                job.start_time = time\n",
    "            \n",
    "            # Determine next event time\n",
    "            next_events = []\n",
    "            if jobs:\n",
    "                next_events.append(jobs[0].release_time)\n",
    "            \n",
    "            for core_id, job in current_jobs.items():\n",
    "                if job:\n",
    "                    execution = self._get_execution_time(job)\n",
    "                    execute_until = time + min(execution, job.remaining)\n",
    "                    next_events.append(execute_until)\n",
    "            \n",
    "            if not next_events:\n",
    "                break\n",
    "                \n",
    "            next_time = min(next_events)\n",
    "            time_step = min(next_time, max_time) - time\n",
    "            \n",
    "            if time_step <= 0:\n",
    "                time = min(next_time, max_time)\n",
    "                continue\n",
    "            \n",
    "            # Execute jobs on all cores\n",
    "            for core_id, job in current_jobs.items():\n",
    "                if job:\n",
    "                    execute_time = min(time_step, job.remaining)\n",
    "                    if execute_time > 0:\n",
    "                        job.remaining -= execute_time\n",
    "                        job.actual_execution += execute_time\n",
    "                        self.cores[core_id].actual_utilization += execute_time\n",
    "                        self.cores[core_id].schedule.append(\n",
    "                            (\n",
    "                                time,\n",
    "                                time + time_step,\n",
    "                                job.task.id,\n",
    "                                job.actual_execution,\n",
    "                            )\n",
    "                        )\n",
    "                        if job.remaining <= 0:\n",
    "                            # Job completed\n",
    "                            response = (time + execute_time) - job.release_time\n",
    "                            job.task.response_time = max(\n",
    "                                job.task.response_time,\n",
    "                                response\n",
    "                            )\n",
    "                            job.task.max_response = max(\n",
    "                                job.task.max_response,\n",
    "                                response\n",
    "                            )\n",
    "                            job.task.total_execution += job.actual_execution\n",
    "                            current_jobs[core_id] = None\n",
    "                        elif (time + execute_time) >= job.deadline:\n",
    "                            # Deadline missed\n",
    "                            job.task.missed_deadlines += 1\n",
    "                            job.task.response_time = max(\n",
    "                                job.task.response_time,\n",
    "                                job.deadline - job.release_time\n",
    "                            )\n",
    "                            job.task.max_response = max(\n",
    "                                job.task.max_response,\n",
    "                                job.deadline - job.release_time\n",
    "                            )\n",
    "                            current_jobs[core_id] = None\n",
    "            \n",
    "            time += time_step\n",
    "        \n",
    "        # Calculate actual utilizations\n",
    "        for core in self.cores:\n",
    "            if max_time > 0:\n",
    "                core.actual_utilization /= max_time    \n",
    "    \n",
    "    def _get_execution_time(self, job):\n",
    "        execution = job.task.net\n",
    "        if random.random() < 0.1:  # 10% chance of overrun\n",
    "            overrun = random.randint(0, job.task.wcet - job.task.net)\n",
    "            execution += overrun\n",
    "            job.overrun = overrun\n",
    "            job.task.overrun += overrun\n",
    "            self.overrun_stats[job.task.id].append(overrun)\n",
    "        return execution\n",
    "    \n",
    "    def analyze_results(self, tasks, max_time, scenario_name):\n",
    "        task_metrics = []\n",
    "        critical_overruns = []\n",
    "        nonlinear_points = []\n",
    "        \n",
    "        for task in tasks:\n",
    "            # Get tasks on the same core for response time calculation\n",
    "            core_tasks = [t for t in tasks if t.core_assignment == task.core_assignment]\n",
    "            \n",
    "            # Calculate theoretical response time based on scheduling policy\n",
    "            if self.is_preemptive:\n",
    "                theoretical_response = self._calculate_response_time_preemptive_rm(task, core_tasks)\n",
    "            else:\n",
    "                theoretical_response = self._calculate_response_time_nonpreemptive_rm(task, core_tasks)\n",
    "            \n",
    "            expected_completions = max(1, task.total_jobs)\n",
    "            actual_completions = expected_completions - task.missed_deadlines\n",
    "            \n",
    "            # Calculate miss rate (task is missed if it has more than one missed deadline job)\n",
    "            miss_ratio = 1.0 if task.missed_deadlines > 1 else 0.0\n",
    "            \n",
    "            avg_response = 0\n",
    "            if actual_completions > 0:\n",
    "                avg_response = task.response_time / actual_completions\n",
    "            \n",
    "            task_metrics.append({\n",
    "                'id': task.id,\n",
    "                'period': task.period,\n",
    "                'wcet': task.wcet,\n",
    "                'net': task.net,\n",
    "                'utilization': task.utilization,\n",
    "                'missed_deadlines': task.missed_deadlines,\n",
    "                'total_jobs': task.total_jobs,\n",
    "                'miss_ratio': miss_ratio, \n",
    "                'theoretical_response': theoretical_response,\n",
    "                'actual_response': task.response_time,\n",
    "                'max_response': task.max_response,\n",
    "                'avg_response': avg_response,\n",
    "                'response_ratio': avg_response / task.period if task.period > 0 else 0,\n",
    "                'core': task.core_assignment,\n",
    "                'total_execution': task.total_execution,\n",
    "                'overrun': task.overrun,\n",
    "                'overrun_ratio': task.overrun / (task.wcet - task.net) if task.wcet > task.net else 0\n",
    "            })\n",
    "            \n",
    "            # Identify critical overruns and nonlinear points\n",
    "            if task.overrun > 0:\n",
    "                if task.max_response > 1.2 * task.period:\n",
    "                    critical_overruns.append({\n",
    "                        'task_id': task.id,\n",
    "                        'period': task.period,\n",
    "                        'wcet': task.wcet,\n",
    "                        'net': task.net,\n",
    "                        'overrun': task.overrun,\n",
    "                        'max_response': task.max_response,\n",
    "                        'miss_ratio': miss_ratio,\n",
    "                        'core': task.core_assignment,\n",
    "                        'utilization': task.utilization\n",
    "                    })\n",
    "                \n",
    "                # Detect nonlinear response increases\n",
    "                if len(self.overrun_stats[task.id]) > 3:\n",
    "                    overruns = np.array(self.overrun_stats[task.id])\n",
    "                    responses = []\n",
    "                    for o in overruns:\n",
    "                        responses.append(task.net + o + task.period * 0.5)  # Simplified model\n",
    "                    \n",
    "                    # Check for nonlinearity\n",
    "                    if np.polyfit(overruns, responses, 2)[0] > 0.1:  # Quadratic coefficient\n",
    "                        nonlinear_points.append({\n",
    "                            'task_id': task.id,\n",
    "                            'threshold': np.mean(overruns),\n",
    "                            'slope': np.polyfit(overruns, responses, 1)[0]\n",
    "                        })\n",
    "        \n",
    "        # Core statistics\n",
    "        core_stats = []\n",
    "        for core in self.cores:\n",
    "            core_tasks = [t for t in task_metrics if t['core'] == core.id]\n",
    "            core_miss_ratio = np.mean([t['miss_ratio'] for t in core_tasks]) if core_tasks else 0\n",
    "            core_stats.append({\n",
    "                'id': core.id,\n",
    "                'utilization': core.utilization,\n",
    "                'actual_utilization': core.actual_utilization,\n",
    "                'miss_ratio': core_miss_ratio,\n",
    "                'task_count': len(core.tasks),\n",
    "                'overrun_tasks': sum(1 for t in core_tasks if t['overrun'] > 0)\n",
    "            })\n",
    "        \n",
    "        # Overall statistics\n",
    "        avg_miss_ratio = np.mean([t['miss_ratio'] for t in task_metrics]) if task_metrics else 0\n",
    "        max_miss_ratio = max([t['miss_ratio'] for t in task_metrics]) if task_metrics else 0\n",
    "        avg_response_ratio = np.mean([t['response_ratio'] for t in task_metrics if t['period'] > 0]) if task_metrics else 0\n",
    "        \n",
    "        critical_paths = self._analyze_critical_paths(tasks)\n",
    "        if critical_paths:\n",
    "            self.plot_milp_analysis(critical_paths, tasks, scenario_name)\n",
    "        return {\n",
    "            'task_metrics': task_metrics,\n",
    "            'core_stats': core_stats,\n",
    "            'critical_paths': critical_paths,\n",
    "            'critical_overruns': critical_overruns,\n",
    "            'nonlinear_points': nonlinear_points,\n",
    "            'avg_miss_ratio': avg_miss_ratio,\n",
    "            'max_miss_ratio': max_miss_ratio,\n",
    "            'avg_response_ratio': avg_response_ratio,\n",
    "            'total_utilization': self.total_utilization,\n",
    "            'overrun_stats': dict(self.overrun_stats)\n",
    "        }\n",
    "\n",
    "    def _calculate_response_time_preemptive_rm(self, task, core_tasks):\n",
    "        \"\"\"Calculate response time for preemptive RM with NET overrun\"\"\"\n",
    "        C_i = task.wcet\n",
    "        Δ_i = task.wcet - task.net  # maximum possible overrun\n",
    "        T_i = task.period\n",
    "        \n",
    "        # Sort tasks by period (RM priority order - shorter period = higher priority)\n",
    "        hp_tasks = sorted([t for t in core_tasks if t.period < task.period], key=lambda x: x.period)\n",
    "        \n",
    "        # Initialize variables for iterative calculation\n",
    "        R_prev = 0\n",
    "        R_current = C_i + Δ_i\n",
    "        \n",
    "        while R_prev != R_current and R_current <= T_i:\n",
    "            R_prev = R_current\n",
    "            sum_interference = 0\n",
    "            \n",
    "            for hp_task in hp_tasks:\n",
    "                C_j = hp_task.wcet\n",
    "                Δ_j = hp_task.wcet - hp_task.net\n",
    "                T_j = hp_task.period\n",
    "                \n",
    "                # Calculate interference term\n",
    "                sum_interference += math.ceil(R_prev / T_j) * (C_j + Δ_j)\n",
    "            \n",
    "            R_current = C_i + Δ_i + sum_interference\n",
    "        \n",
    "        return min(R_current, T_i)\n",
    "\n",
    "    def _calculate_response_time_nonpreemptive_rm(self, task, core_tasks):\n",
    "        \"\"\"Calculate response time for non-preemptive RM with NET overrun\"\"\"\n",
    "        # Sort tasks by period (RM priority order)\n",
    "        sorted_tasks = sorted(core_tasks, key=lambda x: x.period)\n",
    "        \n",
    "        # Find lower priority tasks (longer period)\n",
    "        lp_tasks = [t for t in sorted_tasks if t.period > task.period]\n",
    "        \n",
    "        # Maximum blocking from lower priority tasks\n",
    "        J_i = max((t.wcet + (t.wcet - t.net)) for t in lp_tasks) if lp_tasks else 0\n",
    "        \n",
    "        C_i = task.wcet\n",
    "        Δ_i = task.wcet - task.net\n",
    "        \n",
    "        # Sum of all higher priority tasks (shorter period)\n",
    "        sum_hp = sum((t.wcet + (t.wcet - t.net)) for t in sorted_tasks if t.period < task.period)\n",
    "        \n",
    "        return J_i + C_i + Δ_i + sum_hp\n",
    "\n",
    "    def plot_response_vs_overrun(self, results, scenario_name):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for task in results['task_metrics']:\n",
    "            if task['overrun'] > 0:\n",
    "                overruns = results['overrun_stats'].get(task['id'], [])\n",
    "                if overruns:\n",
    "                    responses = []\n",
    "                    for o in overruns:\n",
    "                        responses.append(task['net'] + o + task['period'] * 0.3)  # Simplified response model\n",
    "                    \n",
    "                    plt.scatter(overruns, responses, label=f\"Task {task['id']}\", alpha=0.6)\n",
    "        \n",
    "        plt.xlabel('Overrun Amount (e)')\n",
    "        plt.ylabel('Response Time')\n",
    "        plt.title(f'Response Time vs NET Overrun\\nScenario: {scenario_name}')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(f'./results/response_vs_overrun/response_vs_overrun_{scenario_name}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_schedulability(self, results, scenario_name):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        util_bins = np.linspace(0, 1, 11)\n",
    "        miss_ratios = []\n",
    "        \n",
    "        for u in util_bins:\n",
    "            tasks_in_bin = [t for t in results['task_metrics'] if (u-0.1) <= t['utilization'] < u]\n",
    "            if tasks_in_bin:\n",
    "                count_gt_0 = sum(1 for t in tasks_in_bin if t['miss_ratio'] > 0)\n",
    "                miss_ratios.append(count_gt_0)\n",
    "            else:\n",
    "                miss_ratios.append(0)\n",
    "        \n",
    "        plt.bar(util_bins, miss_ratios, width=0.1)\n",
    "        plt.xlabel('Task Utilization')\n",
    "        plt.ylabel('Miss count')\n",
    "        plt.title(f'Schedulability Analysis\\nScenario: {scenario_name}')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'./results/schedulability/schedulability_{scenario_name}.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _setup_milp_solver(self):\n",
    "        \"\"\"Initialize MILP solver for critical path analysis\"\"\"\n",
    "        self.milp_solver = pywraplp.Solver.CreateSolver('SCIP')\n",
    "        self.milp_vars = {}\n",
    "    \n",
    "    def _add_milp_constraints(self, tasks):\n",
    "        \"\"\"Add constraints for critical path analysis\"\"\"\n",
    "        # Create variables for each task\n",
    "        for task in tasks:\n",
    "            self.milp_vars[task.id] = self.milp_solver.IntVar(0, task.period, f't{task.id}')\n",
    "        \n",
    "        # Add constraints for dependencies and deadlines\n",
    "        for task in tasks:\n",
    "            # Constraint: Execution time <= Period\n",
    "            self.milp_solver.Add(\n",
    "                self.milp_vars[task.id] <= task.period - task.wcet\n",
    "            )\n",
    "    \n",
    "    def _analyze_critical_paths(self, tasks):\n",
    "        \"\"\"Use MILP to find critical paths and worst-case scenarios\"\"\"\n",
    "        try:\n",
    "            self._setup_milp_solver()\n",
    "            self._add_milp_constraints(tasks)\n",
    "            \n",
    "            # Objective: Maximize response time considering overruns\n",
    "            objective = self.milp_solver.Objective()\n",
    "            for task in tasks:\n",
    "                # Weight by both utilization and potential overrun impact\n",
    "                weight = task.utilization * (task.wcet - task.net)/task.wcet\n",
    "                objective.SetCoefficient(self.milp_vars[task.id], weight)\n",
    "            objective.SetMaximization()\n",
    "            \n",
    "            status = self.milp_solver.Solve()\n",
    "            \n",
    "            if status == pywraplp.Solver.OPTIMAL:\n",
    "                critical_times = {}\n",
    "                for task in tasks:\n",
    "                    crit_time = self.milp_vars[task.id].solution_value()\n",
    "                    # Calculate criticality score (0-1)\n",
    "                    criticality = min(1.0, crit_time/(task.period - task.net))\n",
    "                    critical_times[task.id] = {\n",
    "                        'critical_time': crit_time,\n",
    "                        'criticality': criticality,\n",
    "                        'period': task.period,\n",
    "                        'wcet': task.wcet,\n",
    "                        'net': task.net\n",
    "                    }\n",
    "                return critical_times\n",
    "        except Exception as e:\n",
    "            print(f\"MILP analysis failed: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    def plot_milp_analysis(self, critical_paths, tasks, scenario_name):\n",
    "        \"\"\"Visualize MILP critical path analysis results\"\"\"\n",
    "        if not critical_paths:\n",
    "            return\n",
    "            \n",
    "        # Prepare data\n",
    "        task_ids = []\n",
    "        criticalities = []\n",
    "        periods = []\n",
    "        wcets = []\n",
    "        nets = []\n",
    "        \n",
    "        for task_id, data in critical_paths.items():\n",
    "            task_ids.append(task_id)\n",
    "            criticalities.append(data['criticality'])\n",
    "            periods.append(data['period'])\n",
    "            wcets.append(data['wcet'])\n",
    "            nets.append(data['net'])\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Criticality heatmap - FIXED COLORBAR ISSUE\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sorted_idx = np.argsort(criticalities)[::-1]\n",
    "        sorted_crit = np.array(criticalities)[sorted_idx]\n",
    "        bars = plt.bar(range(len(criticalities)), sorted_crit, \n",
    "                    color=plt.cm.viridis(sorted_crit))\n",
    "        plt.xticks(range(len(criticalities)), np.array(task_ids)[sorted_idx], rotation=45)\n",
    "        plt.xlabel('Task ID')\n",
    "        plt.ylabel('Criticality Score (0-1)')\n",
    "        plt.title('Task Criticality Ranking')\n",
    "        \n",
    "        # Create scalar mappable for colorbar\n",
    "        sm = plt.cm.ScalarMappable(cmap='viridis', \n",
    "                                norm=plt.Normalize(vmin=min(criticalities), \n",
    "                                                vmax=max(criticalities)))\n",
    "        sm.set_array([])\n",
    "        plt.colorbar(sm, ax=plt.gca(), label='Criticality')\n",
    "        \n",
    "        # Criticality vs Period\n",
    "        plt.subplot(2, 2, 2)\n",
    "        scatter = plt.scatter(periods, criticalities, c=wcets, cmap='plasma', s=100)\n",
    "        plt.xlabel('Task Period')\n",
    "        plt.ylabel('Criticality Score')\n",
    "        plt.title('Criticality vs Period (Size=WCET)')\n",
    "        plt.colorbar(scatter, label='WCET')\n",
    "        \n",
    "        # Criticality vs NET/WCET ratio\n",
    "        plt.subplot(2, 2, 3)\n",
    "        ratios = [n/w for n,w in zip(nets, wcets)]\n",
    "        scatter = plt.scatter(ratios, criticalities, c=periods, cmap='cool', s=100)\n",
    "        plt.xlabel('NET/WCET Ratio')\n",
    "        plt.ylabel('Criticality Score')\n",
    "        plt.title('Criticality vs NET/WCET (Color=Period)')\n",
    "        plt.colorbar(scatter, label='Period')\n",
    "        \n",
    "        # Criticality distribution\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.hist(criticalities, bins=20, edgecolor='black')\n",
    "        plt.xlabel('Criticality Score')\n",
    "        plt.ylabel('Number of Tasks')\n",
    "        plt.title('Criticality Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'MILP Critical Path Analysis\\nScenario: {scenario_name}', y=1.02)\n",
    "        plt.savefig(f'./results/milp_analysis/milp_analysis_{scenario_name}.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_milp_report(self, critical_paths):\n",
    "        \"\"\"Generate report of critical paths identified by MILP\"\"\"\n",
    "        report = \"Critical Path Analysis (MILP):\\n\"\n",
    "        report += \"Task ID | Critical Time | Period | WCET | NET\\n\"\n",
    "        report += \"--------|---------------|--------|------|----\\n\"\n",
    "        \n",
    "        for task_id, crit_time in critical_paths.items():\n",
    "            task = next(t for t in self.tasks if t.id == task_id)\n",
    "            report += (f\"{task_id:7} | {crit_time:13.2f} | {task.period:6} | \"\n",
    "            f\"{task.wcet:4} | {task.net:3}\\n\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "\n",
    "\n",
    "def run_rm_scenarios():\n",
    "    scenarios = []\n",
    "    # Vary number of tasks\n",
    "    for n in [10, 50, 100, 200, 400, 500]:\n",
    "        for alloc_policy in ['partitioned_best_fit', 'partitioned_worst_fit', 'partitioned_first_fit', 'partitioned_round_robin','global']:\n",
    "            scenarios.append({\n",
    "                'name': f'{alloc_policy}_RM_{n}tasks_4cores',\n",
    "                'num_cores': 4,\n",
    "                'num_tasks': n,\n",
    "                'scheduling_policy': 'RM',\n",
    "                'allocation_policy': alloc_policy,\n",
    "                'is_preemptive': True,\n",
    "                'max_time': 800,\n",
    "                'target_util': 0.8 * 4  # 80% system utilization\n",
    "            })\n",
    "    \n",
    "    # Vary number of cores\n",
    "    for c in [4, 8, 16, 32]:\n",
    "        for alloc_policy in ['partitioned_best_fit', 'partitioned_worst_fit', 'partitioned_first_fit', 'partitioned_round_robin']:\n",
    "            scenarios.append({\n",
    "                'name': f'{alloc_policy}_RM_100tasks_{c}cores',\n",
    "                'num_cores': c,\n",
    "                'num_tasks': 100,\n",
    "                'scheduling_policy': 'RM',\n",
    "                'allocation_policy': alloc_policy,\n",
    "                'is_preemptive': True,\n",
    "                'max_time': 800,\n",
    "                'target_util': 0.8 * c\n",
    "            })\n",
    "            \n",
    "        # Vary number of cores\n",
    "    for c in [4, 8, 16, 32]:\n",
    "        for alloc_policy in ['global']:\n",
    "            scenarios.append({\n",
    "                'name': f'{alloc_policy}_RM_100tasks_{c}cores',\n",
    "                'num_cores': c,\n",
    "                'num_tasks': 100,\n",
    "                'scheduling_policy': 'RM',\n",
    "                'allocation_policy': alloc_policy,\n",
    "                'is_preemptive': True,\n",
    "                'max_time': 800,\n",
    "                'target_util': 0.5 * c\n",
    "            })\n",
    "    \n",
    "    # Different scheduling policies\n",
    "    for policy in ['partitioned_best_fit', 'global']:\n",
    "        scenarios.append({\n",
    "            'name': f'{policy}_RM_50tasks_8cores',\n",
    "            'num_cores': 8,\n",
    "            'num_tasks': 50,\n",
    "            'scheduling_policy': 'RM',\n",
    "            'allocation_policy': policy,\n",
    "            'is_preemptive': True,\n",
    "            'max_time': 800,\n",
    "            'target_util': 0.8 * 8\n",
    "        })\n",
    "        \n",
    "        # Different scheduling policies\n",
    "    for policy in ['partitioned_best_fit', 'global']:\n",
    "        scenarios.append({\n",
    "            'name': f'{policy}_non_preemptive_RM_50tasks_8cores',\n",
    "            'num_cores': 4,\n",
    "            'num_tasks': 100,\n",
    "            'scheduling_policy': 'RM',\n",
    "            'allocation_policy': policy,\n",
    "            'is_preemptive': False,\n",
    "            'max_time': 800,\n",
    "            'target_util': 0.8 * 4\n",
    "        })\n",
    "    \n",
    "    # Different utilization levels\n",
    "    for util in [0.25, 0.5, 0.75]:\n",
    "        for alloc_policy in ['partitioned_best_fit', 'partitioned_worst_fit']:\n",
    "            scenarios.append({\n",
    "                'name': f'{alloc_policy}_RM_100tasks_4cores_util{util}',\n",
    "                'num_cores': 4,\n",
    "                'num_tasks': 100,\n",
    "                'scheduling_policy': 'RM',\n",
    "                'allocation_policy': alloc_policy,\n",
    "                'is_preemptive': True,\n",
    "                'max_time': 800,\n",
    "                'target_util': util * 4\n",
    "            })\n",
    "    \n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(f\"Running scenario: {scenario['name']}\")\n",
    "        \n",
    "        scheduler = RMScheduler(\n",
    "            num_cores=scenario['num_cores'],\n",
    "            allocation_policy=scenario['allocation_policy'],\n",
    "            is_preemptive=scenario['is_preemptive']\n",
    "        )\n",
    "        \n",
    "        tasks = scheduler.generate_tasks(\n",
    "            scenario['num_tasks'],\n",
    "            scenario.get('target_util')\n",
    "        )\n",
    "        scheduler.allocate_tasks(tasks)\n",
    "        scheduler.simulate(tasks, scenario['max_time'])\n",
    "        results = scheduler.analyze_results(tasks, scenario['max_time'], scenario['name'])\n",
    "        all_results[scenario['name']] = results\n",
    "        \n",
    "        # Generate plots\n",
    "        scheduler.plot_response_vs_overrun(results, scenario['name'])\n",
    "        scheduler.plot_schedulability(results, scenario['name'])\n",
    "    \n",
    "    generate_detailed_report(all_results)\n",
    "\n",
    "def generate_detailed_report(all_results):\n",
    "    with open('./results/comprehensive_rm_report.txt', 'w') as f:\n",
    "        f.write(\"Comprehensive RM Scheduling with NET Overruns Report\\n\")\n",
    "        f.write(\"===================================================\\n\\n\")\n",
    "        \n",
    "        # 1. Upper bounds for response time with NET overruns\n",
    "        f.write(\"1. Upper Bounds for Response Time with NET Overruns:\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            f.write(f\"{scenario}:\\n\")\n",
    "            f.write(f\"- Avg Response/Period: {results['avg_response_ratio']:.2f}\\n\")\n",
    "            f.write(f\"- Miss Rate: {results['avg_miss_ratio']:.2%}\\n\")\n",
    "            f.write(f\"- Max Response/Period: {max(t['response_ratio'] for t in results['task_metrics']):.2f}\\n\")\n",
    "            f.write(f\"- Worst-case Response: {max(t['max_response'] for t in results['task_metrics'] if t['period'] > 0)} units\\n\\n\")\n",
    "        \n",
    "        # 2. Critical overrun values (e)\n",
    "        f.write(\"\\n2. Critical Overrun Values Causing Nonlinear Response:\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if results['critical_overruns']:\n",
    "                f.write(f\"{scenario}:\\n\")\n",
    "                for task in sorted(results['critical_overruns'], key=lambda x: -x['overrun'])[:5]:\n",
    "                    f.write(f\"Task {task['task_id']}: Overrun={task['overrun']} \")\n",
    "                    f.write(f\"(NET={task['net']}, WCET={task['wcet']}) \")\n",
    "                    f.write(f\"Response={task['max_response']} (Period={task['period']})\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        # 3. System sensitive points\n",
    "        f.write(\"\\n3. System Sensitive Points (Nonlinear Response):\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if results['nonlinear_points']:\n",
    "                f.write(f\"{scenario}:\\n\")\n",
    "                for point in results['nonlinear_points']:\n",
    "                    f.write(f\"Task {point['task_id']}: Threshold={point['threshold']:.1f} \")\n",
    "                    f.write(f\"Slope={point['slope']:.2f}\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        # 4. Results for different task counts\n",
    "        f.write(\"\\n4. Results for Different Task Counts:\\n\")\n",
    "        f.write(\"Alloc Policy | Tasks | Avg Miss Ratio | Max Miss Ratio | Avg Response/Period\\n\")\n",
    "        f.write(\"-------------|-------|----------------|----------------|--------------------\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if 'tasks' in scenario:\n",
    "                alloc_policy = scenario.split('_')[0] + '_' + scenario.split('_')[1]\n",
    "                num_tasks = scenario.split('_')[3]\n",
    "                f.write(f\"{alloc_policy:13} | {num_tasks:5} | {results['avg_miss_ratio']:.2%} | \")\n",
    "                f.write(f\"{results['max_miss_ratio']:.2%} | {results['avg_response_ratio']:.2f}\\n\")\n",
    "        \n",
    "        # 5. Results for different core counts\n",
    "        f.write(\"\\n5. Results for Different Core Counts:\\n\")\n",
    "        f.write(\"Alloc Policy | Cores | Avg Miss Ratio | Max Miss Ratio | Avg Response/Period\\n\")\n",
    "        f.write(\"-------------|-------|----------------|----------------|--------------------\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if 'cores' in scenario and 'tasks' in scenario:\n",
    "                parts = scenario.split('_')\n",
    "                alloc_policy = parts[0] + '_' + parts[1]\n",
    "                cores = parts[-2]\n",
    "                f.write(f\"{alloc_policy:13} | {cores:5} | {results['avg_miss_ratio']:.2%} | \")\n",
    "                f.write(f\"{results['max_miss_ratio']:.2%} | {results['avg_response_ratio']:.2f}\\n\")\n",
    "        \n",
    "        # 6. Results for different utilization levels\n",
    "        f.write(\"\\n6. Results for Different Utilization Levels:\\n\")\n",
    "        f.write(\"Alloc Policy | Util | Avg Miss Ratio | Max Miss Ratio | Avg Response/Period\\n\")\n",
    "        f.write(\"-------------|------|----------------|----------------|--------------------\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if 'util' in scenario:\n",
    "                parts = scenario.split('_')\n",
    "                alloc_policy = parts[0] + '_' + parts[1]\n",
    "                util = parts[-1].replace('util', '')\n",
    "                f.write(f\"{alloc_policy:13} | {util:4} | {results['avg_miss_ratio']:.2%} | \")\n",
    "                f.write(f\"{results['max_miss_ratio']:.2%} | {results['avg_response_ratio']:.2f}\\n\")\n",
    "        \n",
    "        # 7. Comparison of allocation policies\n",
    "        f.write(\"\\n7. Comparison of Allocation Policies:\\n\")\n",
    "        f.write(\"Scenario | Alloc Policy | Avg Miss Ratio | Max Miss Ratio | Avg Response/Period\\n\")\n",
    "        f.write(\"---------|--------------|----------------|----------------|--------------------\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            parts = scenario.split('_')\n",
    "            if len(parts) >= 2:\n",
    "                alloc_policy = parts[0] + '_' + parts[1]\n",
    "                f.write(f\"{scenario:8} | {alloc_policy:12} | {results['avg_miss_ratio']:.2%} | \")\n",
    "                f.write(f\"{results['max_miss_ratio']:.2%} | {results['avg_response_ratio']:.2f}\\n\")\n",
    "        # 8. MILP Critical Path Analysis\n",
    "        f.write(\"\\n8. MILP Critical Path Analysis:\\n\")\n",
    "        for scenario, results in all_results.items():\n",
    "            if results.get('critical_paths'):  # Use .get() for safer access\n",
    "                f.write(f\"\\n{scenario}:\\n\")\n",
    "                f.write(\"Task ID | Critical Time | Criticality | Period | WCET | NET\\n\")\n",
    "                f.write(\"--------|---------------|-------------|--------|------|----\\n\")\n",
    "                for task_id, crit_data in results['critical_paths'].items():\n",
    "                    task = next((t for t in results['task_metrics'] if t['id'] == task_id), None)\n",
    "                    if task:  # Only proceed if we found the task\n",
    "                        f.write(f\"{task_id:7} | {crit_data['critical_time']:13.2f} | \"\n",
    "                               f\"{crit_data['criticality']:11.2f} | \"\n",
    "                               f\"{task['period']:6} | {task['wcet']:4} | {task['net']:3}\\n\")\n",
    "        \n",
    "                    \n",
    "    # Save detailed data to CSV for further analysis\n",
    "    with open('./results/detailed_results.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['scenario', 'task_id', 'period', 'wcet', 'net', 'utilization', \n",
    "                     'miss_ratio', 'max_response', 'overrun', 'core']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for scenario, results in all_results.items():\n",
    "            for task in results['task_metrics']:\n",
    "                writer.writerow({\n",
    "                    'scenario': scenario,\n",
    "                    'task_id': task['id'],\n",
    "                    'period': task['period'],\n",
    "                    'wcet': task['wcet'],\n",
    "                    'net': task['net'],\n",
    "                    'utilization': task['utilization'],\n",
    "                    'miss_ratio': task['miss_ratio'],\n",
    "                    'max_response': task['max_response'],\n",
    "                    'overrun': task['overrun'],\n",
    "                    'core': task['core']\n",
    "                })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_rm_scenarios()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
